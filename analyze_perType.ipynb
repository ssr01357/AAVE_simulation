{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_results = json.load(open('/home/yl3427/cylab/AAVE/vllm/aave_llama_final.json'))\n",
    "labels = [\n",
    "    \"Pre-verbal markers\",  # 0\n",
    "    \"Verbal tense-number marking\", # 1\n",
    "    \"Nouns and pronouns\", # 2\n",
    "    \"Negation\", # 3\n",
    "    \"Questions\", # 4\n",
    "    \"Existential and locative construction\", # 5\n",
    "    \"Lexical features\", # 6\n",
    "    \"Phonological features\", # 7\n",
    "    \"Out of list\", # 8\n",
    "]\n",
    "\n",
    "LABEL = labels[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P = \\frac{2a}{2a + b + c}\n",
    "$$\n",
    "\n",
    ", where a is the number of identified features that both annotators agree, and b as well c is the number of identified features that only one annotator agrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlap_ratio(range1, range2):\n",
    "    start = max(range1[0], range2[0])\n",
    "    end = min(range1[1], range2[1])\n",
    "    overlap = max(0, end - start)\n",
    "    average_length = (range1[1] - range1[0] + range2[1] - range2[0]) / 2\n",
    "    return overlap / average_length\n",
    "\n",
    "a_s = {'total':0,} # Both(but from Lee)\n",
    "b_s = {'total':0,} # only Lee\n",
    "# c_s = {'total':0,} # only Chang\n",
    "a_ids = []\n",
    "both_ool = {}\n",
    "\n",
    "threshold = 0.8\n",
    "\n",
    "for i in range(len(annot_results)):\n",
    "    assert annot_results[i]['annotations'][0]['completed_by'] == 4 # Lee\n",
    "    assert annot_results[i]['annotations'][1]['completed_by'] == 2 # Chang\n",
    "    annot_results[i]['annotations'].append({'completed_by':99, 'result':[]}) # intersection\n",
    "\n",
    "    answers_lee = {\"answer1\": [], \"answer2\": [], \"answer3\": [], \"answer4\": [], \"answer5\": [], \"answer6\": []}\n",
    "    answers_chang = {\"answer1\": [], \"answer2\": [], \"answer3\": [], \"answer4\": [], \"answer5\": [], \"answer6\": []}\n",
    "\n",
    "    # Lee's positive cases\n",
    "    for idx1 in range(len(annot_results[i]['annotations'][0]['result'])):\n",
    "        marked_body = annot_results[i]['annotations'][0]['result'][idx1]\n",
    "        if 'start' not in marked_body['value'].keys():\n",
    "            continue\n",
    "        assert marked_body['value']['start'] == marked_body['value']['end']\n",
    "        \n",
    "        if marked_body['value']['start'] == '0':\n",
    "            answers_lee['answer1'].append(marked_body)\n",
    "        elif marked_body['value']['start'] == '1':\n",
    "            answers_lee['answer2'].append(marked_body)\n",
    "        elif marked_body['value']['start'] == '2':\n",
    "            answers_lee['answer3'].append(marked_body)\n",
    "        elif marked_body['value']['start'] == '3':\n",
    "            answers_lee['answer4'].append(marked_body)\n",
    "        elif marked_body['value']['start'] == '4':\n",
    "            answers_lee['answer5'].append(marked_body)\n",
    "        elif marked_body['value']['start'] == '5':\n",
    "            answers_lee['answer6'].append(marked_body)\n",
    "    \n",
    "    # Chang's positive cases\n",
    "    for idx2 in range(len(annot_results[i]['annotations'][1]['result'])):\n",
    "        marked_body = annot_results[i]['annotations'][1]['result'][idx2]\n",
    "        if 'start' not in marked_body['value'].keys():\n",
    "            continue\n",
    "        assert marked_body['value']['start'] == marked_body['value']['end']\n",
    "        \n",
    "        if marked_body['value']['start'] == '0':\n",
    "            answers_chang['answer1'].append(marked_body)\n",
    "        elif marked_body['value']['start'] == '1':\n",
    "            answers_chang['answer2'].append(marked_body)\n",
    "        elif marked_body['value']['start'] == '2':\n",
    "            answers_chang['answer3'].append(marked_body)\n",
    "        elif marked_body['value']['start'] == '3':\n",
    "            answers_chang['answer4'].append(marked_body)\n",
    "        elif marked_body['value']['start'] == '4':\n",
    "            answers_chang['answer5'].append(marked_body)\n",
    "        elif marked_body['value']['start'] == '5':\n",
    "            answers_chang['answer6'].append(marked_body)\n",
    "    \n",
    "    for answer in ['answer1', 'answer2', 'answer3', 'answer4', 'answer5', 'answer6']:\n",
    "        for idx1 in range(len(answers_lee[answer])):\n",
    "            label1 = answers_lee[answer][idx1]['value']['paragraphlabels'][0]\n",
    "            if label1 != LABEL:\n",
    "                continue\n",
    "            text1 = answers_lee[answer][idx1]['value']['text']\n",
    "            range1 = (answers_lee[answer][idx1]['value']['startOffset'], answers_lee[answer][idx1]['value']['endOffset'])\n",
    "\n",
    "            \n",
    "            agreed_candidates = []\n",
    "            for idx2 in range(len(answers_chang[answer])):\n",
    "                label2 = answers_chang[answer][idx2]['value']['paragraphlabels'][0]\n",
    "                range2 = (answers_chang[answer][idx2]['value']['startOffset'], answers_chang[answer][idx2]['value']['endOffset'])\n",
    "                overlap = get_overlap_ratio(range1, range2)\n",
    "                if label1 == label2 and overlap > threshold:\n",
    "                    if agreed_candidates and agreed_candidates[-1][-1] < overlap:\n",
    "                        agreed_candidates.pop()\n",
    "                    elif agreed_candidates and agreed_candidates[-1][-1] > overlap:\n",
    "                        continue\n",
    "                    agreed_candidates.append((idx1, idx2, overlap))\n",
    "\n",
    "            if len(agreed_candidates) >= 1:\n",
    "                a_s['total'] += 1\n",
    "                a_s[label1] = a_s.get(label1, 0) + 1\n",
    "                a_ids.append(answers_lee[answer][idx1]['id'])\n",
    "                annot_results[i]['annotations'][2]['result'].append(answers_lee[answer][idx1])\n",
    "            else:\n",
    "                b_s['total'] += 1\n",
    "                b_s[label1] = b_s.get(label1, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file 16, answer1, for Out of list, Been\n",
      "[(14, 18, 1.0), (14, 19, 1.0), (14, 20, 1.0), (14, 21, 1.0), (14, 22, 1.0)]\n",
      "file 16, answer1, for Out of list, Been\n",
      "[(15, 18, 1.0), (15, 19, 1.0), (15, 20, 1.0), (15, 21, 1.0), (15, 22, 1.0)]\n",
      "file 16, answer1, for Out of list, Been\n",
      "[(16, 18, 1.0), (16, 19, 1.0), (16, 20, 1.0), (16, 21, 1.0), (16, 22, 1.0)]\n",
      "file 16, answer1, for Out of list, Been\n",
      "[(17, 18, 1.0), (17, 19, 1.0), (17, 20, 1.0), (17, 21, 1.0), (17, 22, 1.0)]\n",
      "file 16, answer1, for Out of list, Been\n",
      "[(18, 18, 1.0), (18, 19, 1.0), (18, 20, 1.0), (18, 21, 1.0), (18, 22, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "a_s = {'total':0,} # Both(but from Chang)\n",
    "# b_s = {'total':0,} # only Lee\n",
    "c_s = {'total':0,} # only Chang\n",
    "\n",
    "\n",
    "threshold = 0.8\n",
    "\n",
    "for i in range(len(annot_results)):\n",
    "# for i in range(1):\n",
    "    assert annot_results[i]['annotations'][0]['completed_by'] == 4 # Lee\n",
    "    assert annot_results[i]['annotations'][1]['completed_by'] == 2 # Chang\n",
    "    answers_lee = {\"answer1\": [], \"answer2\": [], \"answer3\": [], \"answer4\": [], \"answer5\": [], \"answer6\": []}\n",
    "    answers_chang = {\"answer1\": [], \"answer2\": [], \"answer3\": [], \"answer4\": [], \"answer5\": [], \"answer6\": []}\n",
    "\n",
    "    # Lee's positive cases\n",
    "    for idx1 in range(len(annot_results[i]['annotations'][0]['result'])):\n",
    "        marked_body = annot_results[i]['annotations'][0]['result'][idx1]['value']\n",
    "        if 'start' not in marked_body.keys():\n",
    "            continue\n",
    "        assert marked_body['start'] == marked_body['end']\n",
    "        \n",
    "        if marked_body['start'] == '0':\n",
    "            answers_lee['answer1'].append(marked_body)\n",
    "        elif marked_body['start'] == '1':\n",
    "            answers_lee['answer2'].append(marked_body)\n",
    "        elif marked_body['start'] == '2':\n",
    "            answers_lee['answer3'].append(marked_body)\n",
    "        elif marked_body['start'] == '3':\n",
    "            answers_lee['answer4'].append(marked_body)\n",
    "        elif marked_body['start'] == '4':\n",
    "            answers_lee['answer5'].append(marked_body)\n",
    "        elif marked_body['start'] == '5':\n",
    "            answers_lee['answer6'].append(marked_body)\n",
    "    \n",
    "    # Chang's positive cases\n",
    "    for idx2 in range(len(annot_results[i]['annotations'][1]['result'])):\n",
    "        marked_body = annot_results[i]['annotations'][1]['result'][idx2]['value']\n",
    "        if 'start' not in marked_body.keys():\n",
    "            continue\n",
    "        assert marked_body['start'] == marked_body['end']\n",
    "        \n",
    "        if marked_body['start'] == '0':\n",
    "            answers_chang['answer1'].append(marked_body)\n",
    "        elif marked_body['start'] == '1':\n",
    "            answers_chang['answer2'].append(marked_body)\n",
    "        elif marked_body['start'] == '2':\n",
    "            answers_chang['answer3'].append(marked_body)\n",
    "        elif marked_body['start'] == '3':\n",
    "            answers_chang['answer4'].append(marked_body)\n",
    "        elif marked_body['start'] == '4':\n",
    "            answers_chang['answer5'].append(marked_body)\n",
    "        elif marked_body['start'] == '5':\n",
    "            answers_chang['answer6'].append(marked_body)\n",
    "    \n",
    "    for answer in ['answer1', 'answer2', 'answer3', 'answer4', 'answer5', 'answer6']:\n",
    "        for idx2 in range(len(answers_chang[answer])):\n",
    "            label2 = answers_chang[answer][idx2]['paragraphlabels'][0]\n",
    "            if label2 != LABEL:\n",
    "                continue\n",
    "            text2 = answers_chang[answer][idx2]['text']\n",
    "            range2 = (answers_chang[answer][idx2]['startOffset'], answers_chang[answer][idx2]['endOffset'])\n",
    "\n",
    "            agreed_candidates = []\n",
    "            for idx1 in range(len(answers_lee[answer])):\n",
    "                label1 = answers_lee[answer][idx1]['paragraphlabels'][0]\n",
    "                range1 = (answers_lee[answer][idx1]['startOffset'], answers_lee[answer][idx1]['endOffset'])\n",
    "                overlap = get_overlap_ratio(range1, range2)\n",
    "                if label1 == label2 and overlap > threshold:\n",
    "                    if agreed_candidates and agreed_candidates[-1][-1] < overlap:\n",
    "                        agreed_candidates.pop()\n",
    "                    elif agreed_candidates and agreed_candidates[-1][-1] > overlap:\n",
    "                        continue\n",
    "                    agreed_candidates.append((idx2, idx1, overlap))\n",
    "\n",
    "            if len(agreed_candidates) > 1:\n",
    "                print(f\"file {i}, {answer}, for {label2}, {text2}\")\n",
    "                print(agreed_candidates)\n",
    "\n",
    "            if len(agreed_candidates) >= 1:\n",
    "                a_s['total'] += 1\n",
    "                a_s[label2] = a_s.get(label2, 0) + 1\n",
    "            else:\n",
    "                c_s['total'] += 1\n",
    "                c_s[label2] = c_s.get(label2, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 0, 0, 0\n",
      "0, 0, 0, 0\n",
      "0, 0, 0, 0\n",
      "0, 0, 0, 0\n",
      "0, 0, 0, 0\n",
      "0, 0, 0, 0\n",
      "0, 0, 0, 0\n",
      "0, 0, 0, 0\n",
      "183, 90, 12, 0.782051282051282\n"
     ]
    }
   ],
   "source": [
    "labels = [\n",
    "    \"Pre-verbal markers\",\n",
    "    \"Verbal tense-number marking\",\n",
    "    \"Nouns and pronouns\",\n",
    "    \"Negation\",\n",
    "    \"Questions\",\n",
    "    \"Existential and locative construction\",\n",
    "    \"Lexical features\",\n",
    "    \"Phonological features\",\n",
    "    \"Out of list\",\n",
    "]\n",
    "iaa_score = {}\n",
    "for label in labels:\n",
    "    a = a_s.get(label, 0)\n",
    "    b = b_s.get(label, 0)\n",
    "    c = c_s.get(label, 0)\n",
    "    support = a\n",
    "    p = 2 * a / (2 * a + b + c) if a > 0 else 0\n",
    "    print(f\"{a}, {b}, {c}, {p}\")\n",
    "    iaa_score[label] = {\"Agreement\": p, \"Support\": support}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pre-verbal markers': {'Agreement': 0, 'Support': 0},\n",
       " 'Verbal tense-number marking': {'Agreement': 0, 'Support': 0},\n",
       " 'Nouns and pronouns': {'Agreement': 0, 'Support': 0},\n",
       " 'Negation': {'Agreement': 0, 'Support': 0},\n",
       " 'Questions': {'Agreement': 0, 'Support': 0},\n",
       " 'Existential and locative construction': {'Agreement': 0, 'Support': 0},\n",
       " 'Lexical features': {'Agreement': 0, 'Support': 0},\n",
       " 'Phonological features': {'Agreement': 0, 'Support': 0},\n",
       " 'Out of list': {'Agreement': 0.782051282051282, 'Support': 183}}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iaa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agree  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prompt  (total, feature) -> anova, t-test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total\n",
    "prompt = [\"CompP\", \"DemoP\", \"LingP\", \"BaseP\"]\n",
    "\n",
    "total_distribution = {\"CompP\": [], \"DemoP\": [], \"LingP\": [], \"BaseP\": []}\n",
    "\n",
    "for i in range(len(annot_results)):\n",
    "    answers = {\"answer1\": [], \"answer2\": [], \"answer3\": [], \"answer4\": [], \"answer5\": [], \"answer6\": []}\n",
    "\n",
    "    for idx1 in range(len(annot_results[i]['annotations'][2]['result'])):\n",
    "        marked_body = annot_results[i]['annotations'][2]['result'][idx1]['value']\n",
    "        if 'start' not in marked_body.keys():\n",
    "            continue\n",
    "        \n",
    "        if marked_body['start'] == '0':\n",
    "            answers['answer1'].append(marked_body)\n",
    "        elif marked_body['start'] == '1':\n",
    "            answers['answer2'].append(marked_body)\n",
    "        elif marked_body['start'] == '2':\n",
    "            answers['answer3'].append(marked_body)\n",
    "        elif marked_body['start'] == '3':\n",
    "            answers['answer4'].append(marked_body)\n",
    "        elif marked_body['start'] == '4':\n",
    "            answers['answer5'].append(marked_body)\n",
    "        elif marked_body['start'] == '5':\n",
    "            answers['answer6'].append(marked_body)\n",
    "\n",
    "    total_distribution[prompt[i%4]].append(len(answers['answer1']))\n",
    "    total_distribution[prompt[i%4]].append(len(answers['answer2']))\n",
    "    total_distribution[prompt[i%4]].append(len(answers['answer3']))\n",
    "    total_distribution[prompt[i%4]].append(len(answers['answer4']))\n",
    "    total_distribution[prompt[i%4]].append(len(answers['answer5']))\n",
    "    total_distribution[prompt[i%4]].append(len(answers['answer6']))\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_distribution\n",
    "df = pd.DataFrame.from_dict(total_distribution)[['DemoP', 'LingP', 'CompP']]\n",
    "df.to_csv(f'distribution_{LABEL}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Source     SS  DF    MS     F  p-unc  p-GG-corr   ng2   eps sphericity  \\\n",
      "0  condition 19.389   2 9.694 8.418  0.001      0.001 0.140 0.846      False   \n",
      "1      Error 80.611  70 1.152   NaN    NaN        NaN   NaN   NaN        NaN   \n",
      "\n",
      "   W-spher  p-spher  \n",
      "0    0.819    0.033  \n",
      "1      NaN      NaN  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>SS</th>\n",
       "      <th>DF</th>\n",
       "      <th>MS</th>\n",
       "      <th>F</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>p-GG-corr</th>\n",
       "      <th>ng2</th>\n",
       "      <th>eps</th>\n",
       "      <th>sphericity</th>\n",
       "      <th>W-spher</th>\n",
       "      <th>p-spher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>condition</td>\n",
       "      <td>19.389</td>\n",
       "      <td>2</td>\n",
       "      <td>9.694</td>\n",
       "      <td>8.418</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.846</td>\n",
       "      <td>False</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Error</td>\n",
       "      <td>80.611</td>\n",
       "      <td>70</td>\n",
       "      <td>1.152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Source     SS  DF    MS     F  p-unc  p-GG-corr   ng2   eps sphericity  \\\n",
       "0  condition 19.389   2 9.694 8.418  0.001      0.001 0.140 0.846      False   \n",
       "1      Error 80.611  70 1.152   NaN    NaN        NaN   NaN   NaN        NaN   \n",
       "\n",
       "   W-spher  p-spher  \n",
       "0    0.819    0.033  \n",
       "1      NaN      NaN  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "import pingouin as pg\n",
    "\n",
    "# From Llama3\n",
    "df_long = df.reset_index().melt(id_vars='index', var_name='condition', value_name='score')\n",
    "df_long.rename(columns={'index': 'subject'}, inplace=True)\n",
    "\n",
    "rm_anova = pg.rm_anova(dv='score', within='condition', subject='subject', data=df_long, detailed=True)\n",
    "print(rm_anova)\n",
    "rm_anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contrast</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>mean(A)</th>\n",
       "      <th>std(A)</th>\n",
       "      <th>mean(B)</th>\n",
       "      <th>std(B)</th>\n",
       "      <th>Paired</th>\n",
       "      <th>Parametric</th>\n",
       "      <th>T</th>\n",
       "      <th>dof</th>\n",
       "      <th>alternative</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>BF10</th>\n",
       "      <th>hedges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>condition</td>\n",
       "      <td>CompP</td>\n",
       "      <td>DemoP</td>\n",
       "      <td>2.167</td>\n",
       "      <td>1.384</td>\n",
       "      <td>1.778</td>\n",
       "      <td>0.866</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.405</td>\n",
       "      <td>35.000</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>condition</td>\n",
       "      <td>CompP</td>\n",
       "      <td>LingP</td>\n",
       "      <td>2.167</td>\n",
       "      <td>1.384</td>\n",
       "      <td>1.139</td>\n",
       "      <td>0.867</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.667</td>\n",
       "      <td>35.000</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.001</td>\n",
       "      <td>38.069</td>\n",
       "      <td>0.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>condition</td>\n",
       "      <td>DemoP</td>\n",
       "      <td>LingP</td>\n",
       "      <td>1.778</td>\n",
       "      <td>0.866</td>\n",
       "      <td>1.139</td>\n",
       "      <td>0.867</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.333</td>\n",
       "      <td>35.000</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.002</td>\n",
       "      <td>16.772</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Contrast      A      B  mean(A)  std(A)  mean(B)  std(B)  Paired  \\\n",
       "0  condition  CompP  DemoP    2.167   1.384    1.778   0.866    True   \n",
       "1  condition  CompP  LingP    2.167   1.384    1.139   0.867    True   \n",
       "2  condition  DemoP  LingP    1.778   0.866    1.139   0.867    True   \n",
       "\n",
       "   Parametric     T    dof alternative  p-unc    BF10  hedges  \n",
       "0        True 1.405 35.000   two-sided  0.169   0.441   0.333  \n",
       "1        True 3.667 35.000   two-sided  0.001  38.069   0.881  \n",
       "2        True 3.333 35.000   two-sided  0.002  16.772   0.730  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_hoc = pg.pairwise_tests(dv='score', within='condition', subject='subject', \n",
    "                              data=df_long, parametric=True, alternative='two-sided', return_desc=True)\n",
    "post_hoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contrast</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>mean(A)</th>\n",
       "      <th>std(A)</th>\n",
       "      <th>mean(B)</th>\n",
       "      <th>std(B)</th>\n",
       "      <th>Paired</th>\n",
       "      <th>Parametric</th>\n",
       "      <th>T</th>\n",
       "      <th>dof</th>\n",
       "      <th>alternative</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>BF10</th>\n",
       "      <th>hedges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>condition</td>\n",
       "      <td>CompP</td>\n",
       "      <td>DemoP</td>\n",
       "      <td>2.167</td>\n",
       "      <td>1.384</td>\n",
       "      <td>1.778</td>\n",
       "      <td>0.866</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.405</td>\n",
       "      <td>35.000</td>\n",
       "      <td>greater</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>condition</td>\n",
       "      <td>CompP</td>\n",
       "      <td>LingP</td>\n",
       "      <td>2.167</td>\n",
       "      <td>1.384</td>\n",
       "      <td>1.139</td>\n",
       "      <td>0.867</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.667</td>\n",
       "      <td>35.000</td>\n",
       "      <td>greater</td>\n",
       "      <td>0.000</td>\n",
       "      <td>76.139</td>\n",
       "      <td>0.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>condition</td>\n",
       "      <td>DemoP</td>\n",
       "      <td>LingP</td>\n",
       "      <td>1.778</td>\n",
       "      <td>0.866</td>\n",
       "      <td>1.139</td>\n",
       "      <td>0.867</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.333</td>\n",
       "      <td>35.000</td>\n",
       "      <td>greater</td>\n",
       "      <td>0.001</td>\n",
       "      <td>33.543</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Contrast      A      B  mean(A)  std(A)  mean(B)  std(B)  Paired  \\\n",
       "0  condition  CompP  DemoP    2.167   1.384    1.778   0.866    True   \n",
       "1  condition  CompP  LingP    2.167   1.384    1.139   0.867    True   \n",
       "2  condition  DemoP  LingP    1.778   0.866    1.139   0.867    True   \n",
       "\n",
       "   Parametric     T    dof alternative  p-unc    BF10  hedges  \n",
       "0        True 1.405 35.000     greater  0.084   0.881   0.333  \n",
       "1        True 3.667 35.000     greater  0.000  76.139   0.881  \n",
       "2        True 3.333 35.000     greater  0.001  33.543   0.730  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_hoc = pg.pairwise_tests(dv='score', within='condition', subject='subject', \n",
    "                              data=df_long, parametric=True, alternative='greater', return_desc=True)\n",
    "post_hoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contrast</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>Paired</th>\n",
       "      <th>Parametric</th>\n",
       "      <th>T</th>\n",
       "      <th>dof</th>\n",
       "      <th>alternative</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>BF10</th>\n",
       "      <th>hedges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>condition</td>\n",
       "      <td>CompP</td>\n",
       "      <td>DemoP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.405</td>\n",
       "      <td>35.000</td>\n",
       "      <td>less</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>condition</td>\n",
       "      <td>CompP</td>\n",
       "      <td>LingP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.667</td>\n",
       "      <td>35.000</td>\n",
       "      <td>less</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>condition</td>\n",
       "      <td>DemoP</td>\n",
       "      <td>LingP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.333</td>\n",
       "      <td>35.000</td>\n",
       "      <td>less</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Contrast      A      B  Paired  Parametric     T    dof alternative  \\\n",
       "0  condition  CompP  DemoP    True        True 1.405 35.000        less   \n",
       "1  condition  CompP  LingP    True        True 3.667 35.000        less   \n",
       "2  condition  DemoP  LingP    True        True 3.333 35.000        less   \n",
       "\n",
       "   p-unc   BF10  hedges  \n",
       "0  0.916  0.881   0.333  \n",
       "1  1.000  0.013   0.881  \n",
       "2  0.999   0.03   0.730  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_hoc = pg.pairwise_tests(dv='score', within='condition', subject='subject', \n",
    "                              data=df_long, parametric=True, alternative='less')\n",
    "post_hoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Out of list'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}